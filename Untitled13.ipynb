{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxA6fipI4dp/EOUht+JsAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manasa-Sairi/NNDL_QUIZ/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgcLQaDGc4Zm"
      },
      "outputs": [],
      "source": [
        "#Q1\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Preprocess images (e.g., normalize pixel values)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Add random noise to create noisy versions of the images\n",
        "noise_factor = 0.2\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "\n",
        "# Clip pixel values to stay within [0, 1] range\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (28, 28, 1)  # Assuming MNIST images with shape (28, 28, 1)\n",
        "\n",
        "# Encoder\n",
        "input_img = Input(shape=input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Display model summary\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVu2aHuQhhfp",
        "outputId": "57834c9f-b2c0-416f-edae-3cc41c6d9f8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 14, 14, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 32)        18464     \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 28, 28, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74497 (291.00 KB)\n",
            "Trainable params: 74497 (291.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "# Compile the model with MSE loss and Adam optimizer\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "history = autoencoder.fit(x_train_noisy, x_train,  # Noisy images as input, clean images as output\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_test_noisy, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iey1JI-Qhspd",
        "outputId": "d634d079-c598-4d9b-c9e9-9fe68ec23f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 170s 361ms/step - loss: 0.1134 - val_loss: 0.1140\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 163s 349ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 174s 371ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 180s 383ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 178s 379ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 166s 354ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 172s 367ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 187s 398ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 173s 368ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 167s 355ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 170s 364ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 161s 344ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 161s 342ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 165s 352ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 169s 360ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 168s 359ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 163s 348ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 171s 364ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 169s 361ms/step - loss: 0.1120 - val_loss: 0.1140\n",
            "Epoch 20/20\n",
            "392/469 [========================>.....] - ETA: 26s - loss: 0.1121"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#monitoring the validation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FDCRfyPzh1zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4\n",
        "# Evaluate the model on a separate set of noisy images\n",
        "evaluation_results = autoencoder.evaluate(x_eval_noisy, x_eval, verbose=0)\n",
        "print(\"Evaluation Results:\")\n",
        "print(\"Mean Squared Error (MSE):\", evaluation_results)\n",
        "\n",
        "# Generate denoised images using the trained autoencoder\n",
        "x_denoised = autoencoder.predict(x_eval_noisy)\n",
        "\n",
        "# Calculate SSIM for each image pair\n",
        "ssim_scores = []\n",
        "for i in range(len(x_eval)):\n",
        "    ssim_score = structural_similarity(x_eval[i], x_denoised[i], multichannel=True)\n",
        "    ssim_scores.append(ssim_score)\n",
        "average_ssim = np.mean(ssim_scores)\n",
        "print(\"Average Structural Similarity Index (SSIM):\", average_ssim)\n",
        "\n",
        "# Visualize some reconstructed images and compare with ground truth\n",
        "n = 10  # Number of images to visualize\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Original (clean) images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_eval[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    # Reconstructed (denoised) images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(x_denoised[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1749AHlTjDuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "# Define a function to create the autoencoder model\n",
        "def create_autoencoder(learning_rate=0.001, batch_size=128, sparsity_reg=0.001):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    # Define encoder and decoder layers\n",
        "    # ...\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                        loss='mean_squared_error')\n",
        "    return autoencoder\n",
        "\n",
        "# Create a KerasRegressor for grid search\n",
        "model = KerasRegressor(build_fn=create_autoencoder, epochs=10, verbose=0)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {'learning_rate': [0.001, 0.01, 0.1],\n",
        "              'batch_size': [64, 128, 256],\n",
        "              'sparsity_reg': [0.001, 0.01, 0.1]}\n",
        "\n",
        "# Perform grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
        "grid_result = grid.fit(x_train_noisy, x_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Best MSE:\", grid_result.best_score_)\n",
        "print(\"Best Parameters:\", grid_result.best_params_)"
      ],
      "metadata": {
        "id": "JwJjXwz0j59q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define hyperparameter distributions for random search\n",
        "param_dist = {'learning_rate': uniform(0.001, 0.1),\n",
        "              'batch_size': randint(64, 256),\n",
        "              'sparsity_reg': uniform(0.001, 0.1)}\n",
        "\n",
        "# Create a KerasRegressor for random search\n",
        "model = KerasRegressor(build_fn=create_autoencoder, epochs=10, verbose=0)\n",
        "\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10,\n",
        "                                   scoring='neg_mean_squared_error', cv=3, verbose=1)\n",
        "random_result = random_search.fit(x_train_noisy, x_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Best MSE:\", random_result.best_score_)\n",
        "print(\"Best Parameters:\", random_result.best_params_)"
      ],
      "metadata": {
        "id": "W7fPQrrlkWnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Define convolutional autoencoder architecture\n",
        "input_img = Input(shape=input_shape)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Add regularization and dropout\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same',\n",
        "           kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder model\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "w9rRxIgFkd16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import mean_squared_error, structural_similarity\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (28, 28, 1)  # Assuming MNIST images with shape (28, 28, 1)\n",
        "\n",
        "# Define autoencoder architecture\n",
        "input_img = Input(shape=input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "decoded = UpSampling2D((2, 2))(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the autoencoder (assuming x_train_noisy and x_train are defined)\n",
        "history = autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate model performance\n",
        "evaluation_results = autoencoder.evaluate(x_eval_noisy, x_eval, verbose=0)\n",
        "print(\"Evaluation Results:\")\n",
        "print(\"Mean Squared Error (MSE):\", evaluation_results)\n",
        "\n",
        "# Generate denoised images using the trained autoencoder\n",
        "x_denoised = autoencoder.predict(x_eval_noisy)\n",
        "\n",
        "# Calculate SSIM for each image pair\n",
        "ssim_scores = []\n",
        "for i in range(len(x_eval)):\n",
        "    ssim_score = structural_similarity(x_eval[i], x_denoised[i], multichannel=True)\n",
        "    ssim_scores.append(ssim_score)\n",
        "average_ssim = tf.reduce_mean(ssim_scores).numpy()\n",
        "print(\"Average Structural Similarity Index (SSIM):\", average_ssim)\n",
        "\n",
        "# Visualize some reconstructed images and compare with ground truth\n",
        "n = 10  # Number of images to visualize\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Original (clean) images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_eval[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    # Reconstructed (denoised) images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(x_denoised[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dsTMDIt0m0c2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}